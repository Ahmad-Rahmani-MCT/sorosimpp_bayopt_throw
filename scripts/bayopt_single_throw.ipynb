{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3ddcfd",
   "metadata": {},
   "source": [
    "neccessary imports, setting the compute device, setting seed, loading the network and scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee1072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using compute device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import random\n",
    "import torch \n",
    "import pickle\n",
    "import optuna \n",
    "\n",
    "## user inputs ## \n",
    "# names and directories \n",
    "model_name = \"forward_MLP.pth\" \n",
    "scaler_model_dir_name = \"network_data\"  \n",
    "input_scaler_filename = \"input_scaler.pkl\" \n",
    "state_scaler_filename = \"state_scaler.pkl\"\n",
    "# neural network configuration  \n",
    "lag_input = 0 \n",
    "lag_state = 1\n",
    "num_hidden_layers = 0\n",
    "hidden_units = 30 \n",
    "input_flat_size = 6 + (lag_state*6) + 3 + (lag_input*3) \n",
    "output_size = 6 \n",
    "# optimization parameters \n",
    "x_intial = np.array([3.3065416622541037e-06, 0, -0.19036912150652113, 6.0826336879046396e-06, 0, -0.3907576704717413])\n",
    "X = np.vstack([x_intial, x_intial]) \n",
    "u_initial = np.array([0,0,0]) \n",
    "U = u_initial\n",
    "delta_umax = 12 \n",
    "umax = 12 \n",
    "tmax = 3  \n",
    "dt = 0.1 # sampling time\n",
    "z_g = -1 # structure height \n",
    "g = 9.8 # gravity acceleration\n",
    "des_land_pos = [0.15, 0.15] # desired landing pose \n",
    "Q = 1 # landing pose weight term  \n",
    "n_trials = 1000 # number of trials\n",
    "\n",
    "# selecting the compute device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(f\"using compute device: {device}\") \n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")   \n",
    "\n",
    "# setting seeds \n",
    "def set_all_seeds(seed: int = 42):\n",
    "    \"\"\"\n",
    "    sets the seeds for python, numpy, and pytoch (CPU & GPU) \n",
    "    \"\"\"\n",
    "    # python random module\n",
    "    random.seed(seed)\n",
    "    # numpy\n",
    "    np.random.seed(seed)\n",
    "    # pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    # pytorch (GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Seeds set to {seed}\") \n",
    "\n",
    "# defining the model \n",
    "class MLP_model(torch.nn.Module): \n",
    "    def __init__(self, input_flat_size:int, hidden_units:int, output_size:int, num_hidden_layers:int) :\n",
    "        super().__init__()\n",
    "        self.input_flat_size = input_flat_size \n",
    "        self.hidden_units = hidden_units \n",
    "        self.output_size = output_size \n",
    "        self.num_hidden_layers = num_hidden_layers \n",
    "\n",
    "        hidden_layers = [] \n",
    "\n",
    "        in_dimension = self.input_flat_size \n",
    "\n",
    "        self.input_layer = torch.nn.Linear(in_features=in_dimension, out_features=self.hidden_units) \n",
    "        \n",
    "        for i in range(self.num_hidden_layers) : \n",
    "            hidden_layers.append(torch.nn.Linear(in_features=self.hidden_units, out_features=self.hidden_units)) \n",
    "            hidden_layers.append(torch.nn.ReLU()) \n",
    "\n",
    "        self.backbone = torch.nn.Sequential(*hidden_layers) \n",
    "        \n",
    "        self.output_layer = torch.nn.Linear(in_features=self.hidden_units, out_features=self.output_size) \n",
    " \n",
    "        self.relu = torch.nn.ReLU()    \n",
    "\n",
    "    def forward(self,x): \n",
    "        out = self.input_layer(x) \n",
    "        out = self.relu(out)\n",
    "        out = self.backbone(out)  \n",
    "        out = self.output_layer(out) \n",
    "        return out  \n",
    "\n",
    "# instantiating an NN object \n",
    "forward_model = MLP_model(input_flat_size=input_flat_size, hidden_units=hidden_units, output_size=output_size, num_hidden_layers=num_hidden_layers) \n",
    "\n",
    "# loading the statedicts \n",
    "script_path = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd() \n",
    "model_data_path = os.path.join(script_path, scaler_model_dir_name) \n",
    "forward_model.load_state_dict(torch.load(os.path.join(model_data_path, model_name), weights_only=True)) \n",
    "forward_model = forward_model.to(device=device) \n",
    "forward_model.eval()  \n",
    "\n",
    "# loading the scalers \n",
    "with open(os.path.join(model_data_path, input_scaler_filename), \"rb\") as file : \n",
    "    input_scaler = pickle.load(file) \n",
    "with open(os.path.join(model_data_path, state_scaler_filename), \"rb\") as file : \n",
    "    state_scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f47479f",
   "metadata": {},
   "source": [
    "defining the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e231e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial) : \n",
    "    # defining the decision variables \n",
    "    u1_step = trial.suggest_float(\"act1_step\", 0, umax) # actuator 1 \n",
    "    u2_step = trial.suggest_float(\"act2_step\", 0, umax) # actuator 2\n",
    "    u3_step = trial.suggest_float(\"act3_step\", 0, umax) # actuator 3 \n",
    "    u_step = np.array([u1_step, u2_step, u3_step]) # shape (,3)\n",
    "    # smoothstep and release time  \n",
    "    t_smoothstep = trial.suggest_float(\"t_smoothstep\", 0, tmax) \n",
    "    t_release = trial.suggest_float(\"t_release\", 0, t_smoothstep) \n",
    "    \n",
    "    # generating the input array based on the smoothstep and sampling time  \n",
    "    ramp_steps = round(t_smoothstep/dt) \n",
    "    release_steps = round(t_release/dt) \n",
    "    smoothstep_factor = np.zeros((ramp_steps,3)) # shape (ramp_steps, 3)\n",
    "    for i in range(ramp_steps) : \n",
    "        x_val = (i-0)/((ramp_steps-1)-0)\n",
    "        smoothstep_factor[i,:] = x_val * x_val * (3 - 2 * x_val) \n",
    "    u_array = smoothstep_factor * u_step # shape (ramp_steps, 3) but factored (broadcasted)\n",
    "\n",
    "    # scaling the input array, initial states and conversion to torch tensor  \n",
    "    u_array_scaled = input_scaler.transform(u_array) \n",
    "    u_array_torch = torch.from_numpy(u_array_scaled).type(torch.float32) \n",
    "    X_init = state_scaler.transform(X) \n",
    "    X_init_scaled = torch.from_numpy(X_init).type(torch.float32) \n",
    "\n",
    "    # rollout (dynamics simulation) \n",
    "    max_lag = max(lag_input, lag_state)\n",
    "    # initial buffer \n",
    "    current_state = X_init_scaled[max_lag,:] \n",
    "    if lag_state == 0 : \n",
    "        past_state = X_init_scaled[max_lag:max_lag] \n",
    "    else : \n",
    "        past_state = X_init_scaled[max_lag-lag_state:max_lag,:] \n",
    "        past_state = torch.flatten(input=past_state) \n",
    "    current_input = u_array_torch[max_lag,:] \n",
    "    if lag_input == 0 : \n",
    "        past_input = u_array_torch[max_lag:max_lag,:]\n",
    "    else : \n",
    "        past_input = u_array_torch[max_lag-lag_input:max_lag,:] \n",
    "        past_input = torch.flatten(input=past_input) \n",
    "\n",
    "    if past_state.size(dim=0) == 0 and past_input.size(dim=0) == 0 : \n",
    "        joined_features = torch.concatenate((current_state, current_input), dim=0) \n",
    "    elif past_state.size(dim=0) != 0 and past_input.size(dim=0) == 0 : \n",
    "        joined_features = torch.concatenate((current_state, past_state, current_input), dim=0)\n",
    "    elif past_state.size(dim=0) == 0 and past_input.size(dim=0) != 0 : \n",
    "        joined_features = torch.concatenate((current_state, current_input, past_input), dim=0) \n",
    "    else : \n",
    "        joined_features = torch.concatenate((current_state, past_state, current_input, past_input), dim=0) \n",
    "\n",
    "    preds = []  \n",
    "\n",
    "    X_buffer = [X_init_scaled]\n",
    "\n",
    "    with torch.inference_mode(): \n",
    "        for i in range(max_lag+1, len(u_array_torch)) : \n",
    "            pred = forward_model(joined_features.unsqueeze(0)) \n",
    "            pred = pred.squeeze(0) \n",
    "\n",
    "            preds.append(pred) \n",
    "            X_buffer.append(pred)\n",
    "\n",
    "            # updating the buffer \n",
    "            current_state = pred\n",
    "            if lag_state == 0 : \n",
    "                past_state = X_buffer[i:i] \n",
    "            else : \n",
    "                past_state = X_buffer[i-lag_state:i,:] \n",
    "                past_state = torch.flatten(input=past_state) \n",
    "            current_input = u_array_torch[i,:] \n",
    "            if lag_input == 0 : \n",
    "                past_input = u_array_torch[i:i,:]\n",
    "            else : \n",
    "                past_input = u_array_torch[i-lag_input:i,:] \n",
    "                past_input = torch.flatten(input=past_input) \n",
    "\n",
    "            if past_state.size(dim=0) == 0 and past_input.size(dim=0) == 0 : \n",
    "                joined_features = torch.concatenate((current_state, current_input), dim=0) \n",
    "            elif past_state.size(dim=0) != 0 and past_input.size(dim=0) == 0 : \n",
    "                joined_features = torch.concatenate((current_state, past_state, current_input), dim=0)\n",
    "            elif past_state.size(dim=0) == 0 and past_input.size(dim=0) != 0 : \n",
    "                joined_features = torch.concatenate((current_state, current_input, past_input), dim=0) \n",
    "            else : \n",
    "                joined_features = torch.concatenate((current_state, past_state, current_input, past_input), dim=0)\n",
    "    \n",
    "    preds_tensor = torch.stack(preds, dim=0) \n",
    "    preds_np = preds_tensor.numpy() \n",
    "\n",
    "    # unscaling the predictions (states corrresponding to the inputs)  \n",
    "    preds_np = state_scaler.inverse_transform(preds_np) \n",
    "\n",
    "    # calculating the veloctiy  \n",
    "    diff = np.diff(preds_np, axis=0) \n",
    "    velocities = np.vstack([np.zeros((1, 6)), diff / dt]) \n",
    "\n",
    "    # predicting the landing positions \n",
    "    delta_z = preds_np[:, -1] - z_g \n",
    "    sqrt_term = velocities[:,-1]**2 + (2 * g * delta_z)\n",
    "    t_flight = (velocities[:,-1] + np.sqrt(sqrt_term)) / g \n",
    "    x_landing = preds_np[:,3] + velocities[:,3] * t_flight\n",
    "    y_landing = preds_np[:,4] + velocities[:,4] * t_flight  \n",
    "\n",
    "    # actual landing based on the release time \n",
    "    act_landing_x = x_landing[release_steps] \n",
    "    act_landing_y = y_landing[release_steps] \n",
    "    land_pos = np.array([act_landing_x, act_landing_y]) \n",
    "\n",
    "    # distance to the goal \n",
    "    dist = np.linalg.norm(des_land_pos - land_pos) \n",
    "\n",
    "    cost = Q * dist \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3514f01d",
   "metadata": {},
   "source": [
    "bayesian optimization settings and initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
