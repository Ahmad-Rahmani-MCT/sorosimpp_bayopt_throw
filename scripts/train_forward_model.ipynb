{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf35b72",
   "metadata": {},
   "source": [
    "neccessary imports, selecting the compute device, setting seed, data loading and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54af7e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using compute device: cpu\n",
      "shape of the dataset:  (36380, 9)\n"
     ]
    }
   ],
   "source": [
    "# setting the seeds \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import random \n",
    "import torch \n",
    "import pandas as pd  \n",
    "\n",
    "##  user inputs ## \n",
    "# names and directories \n",
    "dataset_dir_name = \"datasets\" # directory to access the dataset and save the dataset plots\n",
    "dataset_filename = \"amprs_10hz_36k.csv\" # filename of the dataset \n",
    "data_plot_dir_name = \"amprs_10hz_36k_plots\" # directory name to save plots within dataset_dir_name\n",
    "network_data_dir_name = \"network_data\" # directory to save the scalers and networks weights and biases\n",
    "# determining the indices to reference the dataset  \n",
    "input_1_index = 0 \n",
    "input_2_index = 1 \n",
    "input_3_index = 2 \n",
    "midsection_x_index = 3 \n",
    "midsection_y_index = 4 \n",
    "midsection_z_index = 5 \n",
    "ee_x_index = 6 \n",
    "ee_y_index = 7 \n",
    "ee_z_index = 8 \n",
    "input_start_index = 0  \n",
    "input_stop_index = 3 \n",
    "state_start_index = 3 \n",
    "state_stop_index = 9  \n",
    "# train, validation and testing split \n",
    "train_percent = 0.7 \n",
    "valid_percent = 0.15 \n",
    "test_percent = 0.15  \n",
    "# state and input lags \n",
    "lag_input = 0 \n",
    "lag_state = 1   \n",
    "# nn configuration \n",
    "num_hidden_layers = 0\n",
    "hidden_units = 30  \n",
    "learning_rate_autoregressive = 0.0001 \n",
    "\n",
    "\n",
    "# selecting the compute device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(f\"using compute device: {device}\") \n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")  \n",
    "\n",
    "# setting the seeds \n",
    "def set_all_seeds(seed: int = 42):\n",
    "    \"\"\"\n",
    "    sets the seeds for python, numpy, and pytoch (CPU & GPU) \n",
    "    \"\"\"\n",
    "    # python random module\n",
    "    random.seed(seed)\n",
    "    # numpy\n",
    "    np.random.seed(seed)\n",
    "    # pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    # pytorch (GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Seeds set to {seed}\") \n",
    "\n",
    "# setting up directory paths and loading the dataset\n",
    "script_directory = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd() \n",
    "dataset_path = os.path.join(script_directory, dataset_dir_name) \n",
    "def load_data(file_path: str): \n",
    "    \"\"\"\n",
    "    Reads a csv and returns a numpy array of all the data \n",
    "    SETS THE INDEX TO THE TIME COLUMN\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path) \n",
    "    df.set_index('time',inplace=True)  \n",
    "    data = df.to_numpy() \n",
    "    return data   \n",
    "dataset = load_data(os.path.join(dataset_path, dataset_filename)) \n",
    "print(\"shape of the dataset: \", dataset.shape)  \n",
    "\n",
    "# data plot directory \n",
    "data_plot_path = os.path.join(dataset_path, data_plot_dir_name) \n",
    "os.makedirs(data_plot_path, exist_ok=True) \n",
    "\n",
    "# plotting  \n",
    "# 3d trajectory plot \n",
    "plot_name = \"x_y_z plot.png\"  \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(dataset[:, ee_x_index], dataset[:, ee_y_index], dataset[:, ee_z_index], s=5)\n",
    "ax.scatter(dataset[:, midsection_x_index], dataset[:, midsection_y_index], dataset[:, midsection_z_index], s=5)\n",
    "ax.set_zlim(-0.4, 0)\n",
    "ax.set_xlabel('EE_X[m]')\n",
    "ax.set_ylabel('EE_Y[m]')\n",
    "ax.set_zlabel('EE_Z[m]')\n",
    "ax.set_title('3D EE Trajectory')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(data_plot_path, plot_name), dpi=300, bbox_inches=\"tight\")\n",
    "plt.close() \n",
    "# 3d ee trajectory plot \n",
    "plot_name = \"ee_x_y_z plot.png\"  \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(dataset[:, ee_x_index], dataset[:, ee_y_index], dataset[:, ee_z_index], s=5)\n",
    "ax.set_zlim(-0.4, 0)\n",
    "ax.set_xlabel('EE_X[m]')\n",
    "ax.set_ylabel('EE_Y[m]')\n",
    "ax.set_zlabel('EE_Z[m]')\n",
    "ax.set_title('3D EE Trajectory')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(data_plot_path, plot_name), dpi=300, bbox_inches=\"tight\")\n",
    "plt.close() \n",
    "# 2d ee trajectory plot \n",
    "plot_name = \"ee_x_y_plot.png\"  \n",
    "plt.figure()\n",
    "plt.scatter(dataset[:,ee_x_index],dataset[:,ee_y_index], s=5)\n",
    "plt.xlabel('EE_x[m]') \n",
    "plt.ylabel('EE_y[m]') \n",
    "plt.title('2D EE Trajectory')  \n",
    "plt.tight_layout()  \n",
    "plt.savefig(os.path.join(data_plot_path, plot_name), dpi=300, bbox_inches=\"tight\") \n",
    "plt.close()  \n",
    "# actuator inputs plots \n",
    "for i in range(input_stop_index) : \n",
    "    plot_name = f\"u{i+1}_plot.png\"   \n",
    "    plt.figure()\n",
    "    plt.plot(dataset[:,i])  \n",
    "    plt.xlabel('Sample') \n",
    "    plt.ylabel(f\"Actuator {i+1} Value\") \n",
    "    plt.title(f\"Actuator {i+1} Inputs\")  \n",
    "    plt.tight_layout()  \n",
    "    plt.savefig(os.path.join(data_plot_path, plot_name), dpi=300, bbox_inches=\"tight\") \n",
    "    plt.close()  \n",
    "# state plots \n",
    "for i in range(state_start_index,state_stop_index) : \n",
    "    plot_name = f\"x_{i+1}_plot.png\"   \n",
    "    plt.figure()\n",
    "    plt.plot(dataset[:,i])  \n",
    "    plt.xlabel('Sample') \n",
    "    plt.ylabel(f\"State {i+1} Value\") \n",
    "    plt.title(f\"State {i+1} Values\")  \n",
    "    plt.tight_layout()  \n",
    "    plt.savefig(os.path.join(data_plot_path, plot_name), dpi=300, bbox_inches=\"tight\") \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c2453",
   "metadata": {},
   "source": [
    "shifting the data and train, validation and testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9b589ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape:  (36380, 3)\n",
      "states shape:  (36380, 6)\n",
      "U and X train split shape:  (25466, 3) (25466, 6)\n",
      "U and X valid split shape:  (5457, 3) (5457, 6)\n",
      "U and X test split shape:  (5457, 3) (5457, 6)\n"
     ]
    }
   ],
   "source": [
    "# shifting the dataset \n",
    "U = dataset[:,input_start_index:input_stop_index] \n",
    "X = dataset[:,state_start_index:state_stop_index] \n",
    "print(\"inputs shape: \", U.shape) \n",
    "print(\"states shape: \", X.shape)  \n",
    "\n",
    "# train, validation and testing split \n",
    "def train_valid_test_split(dataset: np.array, train_percent: int, valid_percent: int) : \n",
    "    \"\"\"\n",
    "    splits a dataset into training, validation and testing sets\n",
    "    \"\"\"\n",
    "    len_data = len(dataset) \n",
    "    train_size = int(train_percent*len_data) \n",
    "    valid_size = int(valid_percent*len_data) \n",
    "    train_data = dataset[0:train_size] \n",
    "    valid_data = dataset[train_size:train_size+valid_size] \n",
    "    test_data = dataset[train_size+valid_size:] \n",
    "    return train_data, valid_data, test_data  \n",
    "U_train, U_valid, U_test = train_valid_test_split(dataset=U, train_percent=train_percent, valid_percent=valid_percent) \n",
    "X_train, X_valid, X_test = train_valid_test_split(dataset=X, train_percent=train_percent, valid_percent=valid_percent) \n",
    "print(\"U and X train split shape: \", U_train.shape, X_train.shape) \n",
    "print(\"U and X valid split shape: \", U_valid.shape, X_valid.shape) \n",
    "print(\"U and X test split shape: \", U_test.shape, X_test.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c9142",
   "metadata": {},
   "source": [
    "scaling the datasets and saving the scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3eb0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "input_scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "state_scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "input_scaler.fit(U_train)   \n",
    "state_scaler.fit(X_train) \n",
    "U_train_scaled = input_scaler.transform(U_train) \n",
    "U_valid_scaled = input_scaler.transform(U_valid) \n",
    "U_test_scaled = input_scaler.transform(U_test)  \n",
    "X_train_scaled = state_scaler.transform(X_train) \n",
    "X_valid_scaled = state_scaler.transform(X_valid) \n",
    "X_test_scaled = state_scaler.transform(X_test)  \n",
    "# saving the scalers  \n",
    "network_data_dir_path = os.path.join(script_directory, network_data_dir_name) \n",
    "os.makedirs(network_data_dir_path, exist_ok=True)\n",
    "import pickle\n",
    "input_scaler_filename = \"input_scaler_lines.pkl\" \n",
    "state_scaler_filename = \"state_scaler_lines.pkl\" \n",
    "with open(os.path.join(network_data_dir_path, input_scaler_filename), \"wb\") as file : \n",
    "    pickle.dump(input_scaler, file=file)\n",
    "with open(os.path.join(network_data_dir_path, state_scaler_filename), \"wb\") as file : \n",
    "    pickle.dump(state_scaler, file=file) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdaec20",
   "metadata": {},
   "source": [
    "creating features and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4b238a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the training features and labels:  (25464, 15) (25464, 6)\n",
      "shape of the validation features and labels:  (5455, 15) (5455, 6)\n",
      "shape of the testing features and labels:  (5455, 15) (5455, 6)\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(U: np.array, X: np.array, lag_input: int, lag_state: int) :  \n",
    "    \"\"\"\n",
    "    creates features and labels based on the state and input lag for a forward dynamical model \n",
    "    assumes the following x_k+1 = f(x_k,x_k-1:nx, u_k, u_k-1:nu)\n",
    "    \"\"\"\n",
    "    \n",
    "    features = [] \n",
    "    labels = [] \n",
    "\n",
    "    max_lag = max(lag_input, lag_state)\n",
    "\n",
    "    for i in range(max_lag, len(U)-1) : \n",
    "        current_state = X[i,:] \n",
    "        if lag_state == 0 : \n",
    "            past_states = X[i:i] \n",
    "        else : \n",
    "            past_states = X[i-lag_state:i,:] \n",
    "            past_states = past_states.flatten('C') \n",
    "        current_input = U[i,:] \n",
    "        if lag_input == 0 : \n",
    "            past_inputs = U[i:i] \n",
    "        else : \n",
    "            past_inputs = U[i-lag_input:i,:] \n",
    "            past_inputs = past_inputs.flatten('C')\n",
    "        \n",
    "        if past_states.size == 0 and past_inputs.size == 0 : \n",
    "            joined_features = np.concatenate((current_state, current_input), axis=0) \n",
    "        elif past_states.size != 0 and past_inputs.size == 0 : \n",
    "            joined_features = np.concatenate((current_state, past_states, current_input), axis=0)\n",
    "        elif past_states.size == 0 and past_inputs.size != 0 : \n",
    "            joined_features = np.concatenate((current_state, current_input, past_inputs), axis=0) \n",
    "        else : \n",
    "            joined_features = np.concatenate((current_state, past_states, current_input, past_inputs), axis=0) \n",
    "\n",
    "        features.append(joined_features) \n",
    "        labels.append(X[i+1]) \n",
    "    \n",
    "    features = np.array(features) \n",
    "    labels = np.array(labels)  \n",
    "\n",
    "    return features, labels \n",
    "\n",
    "train_features, train_labels = prepare_dataset(U=U_train_scaled, X=X_train_scaled, lag_input=lag_input, lag_state=lag_state) \n",
    "print(\"shape of the training features and labels: \", train_features.shape, train_labels.shape) \n",
    "valid_features, valid_labels = prepare_dataset(U=U_valid_scaled, X=X_valid_scaled, lag_input=lag_input, lag_state=lag_state) \n",
    "print(\"shape of the validation features and labels: \", valid_features.shape, valid_labels.shape) \n",
    "test_features, test_labels = prepare_dataset(U=U_test_scaled, X=X_test_scaled, lag_input=lag_input, lag_state=lag_state) \n",
    "print(\"shape of the testing features and labels: \", test_features.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca6d96",
   "metadata": {},
   "source": [
    "defining and creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aff60cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MLP_model                                [1, 6]                    --\n",
      "├─Linear: 1-1                            [1, 30]                   480\n",
      "├─ReLU: 1-2                              [1, 30]                   --\n",
      "├─Sequential: 1-3                        [1, 30]                   --\n",
      "├─Linear: 1-4                            [1, 6]                    186\n",
      "==========================================================================================\n",
      "Total params: 666\n",
      "Trainable params: 666\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class MLP_model(torch.nn.Module): \n",
    "    def __init__(self, input_flat_size:int, hidden_units:int, output_size:int, num_hidden_layers:int) :\n",
    "        super().__init__()\n",
    "        self.input_flat_size = input_flat_size \n",
    "        self.hidden_units = hidden_units \n",
    "        self.output_size = output_size \n",
    "        self.num_hidden_layers = num_hidden_layers \n",
    "\n",
    "        hidden_layers = [] \n",
    "\n",
    "        in_dimension = self.input_flat_size \n",
    "\n",
    "        self.input_layer = torch.nn.Linear(in_features=in_dimension, out_features=self.hidden_units) \n",
    "        \n",
    "        for i in range(self.num_hidden_layers) : \n",
    "            hidden_layers.append(torch.nn.Linear(in_features=self.hidden_units, out_features=self.hidden_units)) \n",
    "            hidden_layers.append(torch.nn.ReLU()) \n",
    "\n",
    "        self.backbone = torch.nn.Sequential(*hidden_layers) \n",
    "        \n",
    "        self.output_layer = torch.nn.Linear(in_features=self.hidden_units, out_features=self.output_size) \n",
    " \n",
    "        self.relu = torch.nn.ReLU()    \n",
    "\n",
    "    def forward(self,x): \n",
    "        out = self.input_layer(x) \n",
    "        out = self.relu(out)\n",
    "        out = self.backbone(out)  \n",
    "        out = self.output_layer(out) \n",
    "        return out \n",
    "    \n",
    "\n",
    "\n",
    "input_flat_size = train_features.shape[1]\n",
    "output_size = train_labels.shape[1] \n",
    "\n",
    "forward_model = MLP_model(input_flat_size=input_flat_size, hidden_units=hidden_units, output_size=output_size, num_hidden_layers=num_hidden_layers) \n",
    "\n",
    "from torchinfo import summary \n",
    "print(summary(model=forward_model, input_size=(1,input_flat_size)))\n",
    "\n",
    "optimizer_autoregressive = torch.optim.Adam(forward_model.parameters(), lr=learning_rate_autoregressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b34d6",
   "metadata": {},
   "source": [
    "Defining the autoregressive training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a62b0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoregressive(model: torch.nn.Module, U_scaled_train: np.array, X_scaled_train: np.array, \n",
    "                         U_scaled_valid: np.array, X_scaled_valid: np.array, \n",
    "                         lag_input: int, lag_state: int, \n",
    "                         epochs: int, optimizer: torch.optim.Optimizer, loss_fn: torch.nn.Module, \n",
    "                         model_name: str, chunk_length: int, early_stopping_call = None):   \n",
    "    \n",
    "    results = {\"train_loss\": [], \"valid_loss\": []}\n",
    "\n",
    "    U_train = torch.from_numpy(U_scaled_train).type(torch.float32)\n",
    "    X_train = torch.from_numpy(X_scaled_train).type(torch.float32)\n",
    "    U_valid = torch.from_numpy(U_scaled_valid).type(torch.float32)\n",
    "    X_valid = torch.from_numpy(X_scaled_valid).type(torch.float32)  \n",
    "\n",
    "    max_lag = max(lag_input, lag_state)\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "\n",
    "        X_train_buffer = X_train.clone()\n",
    "        X_valid_buffer = X_valid.clone()\n",
    "\n",
    "        model.train() \n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        preds = []  \n",
    "        labels = [] \n",
    "\n",
    "        total_loss = 0 \n",
    "        step = 0  \n",
    "        counter = 0\n",
    "\n",
    "        # initial buffer filled with ground truth \n",
    "        current_state = X_train[max_lag,:] \n",
    "        if lag_state == 0 : \n",
    "            past_state = X_train[max_lag:max_lag] \n",
    "        else : \n",
    "            past_state = X_train[max_lag-lag_state:max_lag,:] \n",
    "            past_state = torch.flatten(input=past_state) \n",
    "        current_input = U_train[max_lag,:] \n",
    "        if lag_input == 0 : \n",
    "            past_input = U_train[max_lag:max_lag,:]\n",
    "        else : \n",
    "            past_input = U_train[max_lag-lag_input:max_lag,:] \n",
    "            past_input = torch.flatten(input=past_input) \n",
    "\n",
    "        if past_state.size(dim=0) == 0 and past_input.size(dim=0) == 0 : \n",
    "            joined_features = torch.concatenate((current_state, current_input), dim=0) \n",
    "        elif past_state.size(dim=0) != 0 and past_input.size(dim=0) == 0 : \n",
    "            joined_features = torch.concatenate((current_state, past_state, current_input), dim=0)\n",
    "        elif past_state.size(dim=0) == 0 and past_input.size(dim=0) != 0 : \n",
    "            joined_features = torch.concatenate((current_state, current_input, past_input), dim=0) \n",
    "        else : \n",
    "            joined_features = torch.concatenate((current_state, past_state, current_input, past_input), dim=0)  \n",
    "\n",
    "        for i in range(max_lag+1, len(U_train)) : \n",
    "\n",
    "            pred = model(joined_features.unsqueeze(0)) \n",
    "            pred = pred.squeeze(0) \n",
    "\n",
    "            step += 1 \n",
    "\n",
    "            preds.append(pred)  \n",
    "\n",
    "            labels.append(X_train[i])\n",
    "\n",
    "            X_train_buffer[i,:] = pred  \n",
    "\n",
    "            if i < len(U_train) - 1 :\n",
    "\n",
    "                # buffer update \n",
    "                current_state = pred\n",
    "                if lag_state == 0 : \n",
    "                    past_state = X_train_buffer[i:i] \n",
    "                else : \n",
    "                    past_state = X_train_buffer[i-lag_state:i,:] \n",
    "                    past_state = torch.flatten(input=past_state)\n",
    "                current_input = U_train[i,:] \n",
    "                if lag_input == 0 : \n",
    "                    past_input = U_train[i:i,:]\n",
    "                else : \n",
    "                    past_input = U_train[i-lag_input:i,:] \n",
    "                    past_input = torch.flatten(input=past_input) \n",
    "\n",
    "                if past_state.size(dim=0) == 0 and past_input.size(dim=0) == 0 : \n",
    "                    joined_features = torch.concatenate((current_state, current_input), dim=0) \n",
    "                elif past_state.size(dim=0) != 0 and past_input.size(dim=0) == 0 : \n",
    "                    joined_features = torch.concatenate((current_state, past_state, current_input), dim=0)\n",
    "                elif past_state.size(dim=0) == 0 and past_input.size(dim=0) != 0 : \n",
    "                    joined_features = torch.concatenate((current_state, current_input, past_input), dim=0) \n",
    "                else : \n",
    "                    joined_features = torch.concatenate((current_state, past_state, current_input, past_input), dim=0) \n",
    "\n",
    "            else : \n",
    "                pass  \n",
    "\n",
    "            if step == chunk_length or i == len(U_train) - 1:  \n",
    "\n",
    "                preds_tensor = torch.stack(preds, dim=0)  \n",
    "\n",
    "                labels_tensor = torch.stack(labels, dim=0)\n",
    "\n",
    "                loss = loss_fn(preds_tensor, labels_tensor)  \n",
    "\n",
    "                loss.backward() \n",
    "                total_loss += loss.item()\n",
    "                optimizer.step()  \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "\n",
    "                current_state = current_state.detach() \n",
    "                X_train_buffer = X_train_buffer.detach() \n",
    "                joined_features = joined_features.detach()\n",
    "\n",
    "                total_loss += loss.item() \n",
    "                \n",
    "                step = 0 \n",
    "                preds = [] \n",
    "                labels = []   \n",
    "                counter += 1  \n",
    "            else : \n",
    "                pass\n",
    "\n",
    "        train_loss = total_loss/counter\n",
    "\n",
    "        # validation \n",
    "        model.eval() \n",
    "\n",
    "        preds = []\n",
    "\n",
    "        # initial buffer filled with ground truth \n",
    "        current_state = X_valid[max_lag,:] \n",
    "        if lag_state == 0 : \n",
    "            past_state = X_valid[max_lag:max_lag] \n",
    "        else : \n",
    "            past_state = X_valid[max_lag-lag_state:max_lag,:] \n",
    "            past_state = torch.flatten(input=past_state) \n",
    "        current_input = U_valid[max_lag,:] \n",
    "        if lag_input == 0 : \n",
    "            past_input = U_valid[max_lag:max_lag,:]\n",
    "        else : \n",
    "            past_input = U_valid[max_lag-lag_input:max_lag,:] \n",
    "            past_input = torch.flatten(input=past_input) \n",
    "\n",
    "        if past_state.size(dim=0) == 0 and past_input.size(dim=0) == 0 : \n",
    "            joined_features = torch.concatenate((current_state, current_input), dim=0) \n",
    "        elif past_state.size(dim=0) != 0 and past_input.size(dim=0) == 0 : \n",
    "            joined_features = torch.concatenate((current_state, past_state, current_input), dim=0)\n",
    "        elif past_state.size(dim=0) == 0 and past_input.size(dim=0) != 0 : \n",
    "            joined_features = torch.concatenate((current_state, current_input, past_input), dim=0) \n",
    "        else : \n",
    "            joined_features = torch.concatenate((current_state, past_state, current_input, past_input), dim=0) \n",
    "        \n",
    "        with torch.inference_mode() :  \n",
    "\n",
    "            for i in range(max_lag+1, len(U_valid)) : \n",
    "\n",
    "                pred = model(joined_features.unsqueeze(0)) \n",
    "                pred = pred.squeeze(0) \n",
    "\n",
    "                preds.append(pred) \n",
    "\n",
    "                X_valid_buffer[i,:] = pred  \n",
    "\n",
    "                if i < len(U_valid) - 1 : \n",
    "\n",
    "                    # buffer update \n",
    "                    current_state = pred\n",
    "                    if lag_state == 0 : \n",
    "                        past_state = X_valid[i:i] \n",
    "                    else : \n",
    "                        past_state = X_valid_buffer[i-lag_state:i,:] \n",
    "                        past_state = torch.flatten(input=past_state)\n",
    "                    current_input = U_valid[i,:] \n",
    "                    if lag_input == 0 : \n",
    "                        past_input = U_valid[i:i,:]\n",
    "                    else : \n",
    "                        past_input = U_valid[i-lag_input:i,:] \n",
    "                        past_input = torch.flatten(input=past_input)  \n",
    "\n",
    "                    if past_state.size(dim=0) == 0 and past_input.size(dim=0) == 0 : \n",
    "                        joined_features = torch.concatenate((current_state, current_input), dim=0) \n",
    "                    elif past_state.size(dim=0) != 0 and past_input.size(dim=0) == 0 : \n",
    "                        joined_features = torch.concatenate((current_state, past_state, current_input), dim=0)\n",
    "                    elif past_state.size(dim=0) == 0 and past_input.size(dim=0) != 0 : \n",
    "                        joined_features = torch.concatenate((current_state, current_input, past_input), dim=0) \n",
    "                    else : \n",
    "                        joined_features = torch.concatenate((current_state, past_state, current_input, past_input), dim=0)\n",
    "                     \n",
    "\n",
    "                else : \n",
    "                    pass\n",
    "\n",
    "        preds_tensor = torch.stack(preds, dim=0) \n",
    "\n",
    "        targets = X_valid[max_lag+1:] \n",
    "\n",
    "        loss = loss_fn(preds_tensor, targets) \n",
    "\n",
    "        valid_loss = loss.item() \n",
    "\n",
    "        print(\n",
    "        f\"Model: {model_name} |\"\n",
    "        f\"Epoch: {epoch + 1} | \"\n",
    "        f\"Train Loss: {train_loss:.6f} | \" \n",
    "        f\"Validation_Loss: {valid_loss:.6f} | \" \n",
    "        ) \n",
    "\n",
    "        results[\"train_loss\"].append(train_loss) \n",
    "        results[\"valid_loss\"].append(valid_loss)\n",
    "\n",
    "        if early_stopping_call is not None: \n",
    "            early_stopping_call(valid_loss) \n",
    "            if early_stopping_call.early_stop : \n",
    "                print(\"Early Stopping Triggered\") \n",
    "                break \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a0d1d",
   "metadata": {},
   "source": [
    "defining early stopping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3785ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=6, min_delta=0.0):\n",
    "        \"\"\"\n",
    "        patience: number of epochs to wait for improvement\n",
    "        min_delta: minimum improvement in validation loss to count as progress\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = np.inf\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31616e9a",
   "metadata": {},
   "source": [
    "training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce37b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
