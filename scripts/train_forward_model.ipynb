{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf35b72",
   "metadata": {},
   "source": [
    "neccessary imports, selecting the compute device, setting seed, data loading and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54af7e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using compute device: cpu\n",
      "shape of the dataset:  (36380, 9)\n"
     ]
    }
   ],
   "source": [
    "# setting the seeds \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import random \n",
    "import torch \n",
    "import pandas as pd  \n",
    "\n",
    "##  user inputs ## \n",
    "# names and directories \n",
    "dataset_dir_name = \"datasets\" # directory to access the dataset and save the dataset plots\n",
    "dataset_filename = \"amprs_10hz_36k.csv\" # filename of the dataset \n",
    "data_plot_dir_name = \"amprs_10hz_36k_plots\" # directory name to save plots within dataset_dir_name\n",
    "network_data_dir_name = \"network_data\" # directory to save the scalers and networks weights and biases\n",
    "# determining the indices to reference the dataset  \n",
    "input_1_index = 0 \n",
    "input_2_index = 1 \n",
    "input_3_index = 2 \n",
    "midsection_x_index = 3 \n",
    "midsection_y_index = 4 \n",
    "midsection_z_index = 5 \n",
    "ee_x_index = 6 \n",
    "ee_y_index = 7 \n",
    "ee_z_index = 8 \n",
    "input_start_index = 0  \n",
    "input_stop_index = 3 \n",
    "state_start_index = 3 \n",
    "state_stop_index = 9  \n",
    "# train, validation and testing split \n",
    "train_percent = 0.7 \n",
    "valid_percent = 0.15 \n",
    "test_percent = 0.15 \n",
    "\n",
    "\n",
    "# selecting the compute device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(f\"using compute device: {device}\") \n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")  \n",
    "\n",
    "# setting the seeds \n",
    "def set_all_seeds(seed: int = 42):\n",
    "    \"\"\"\n",
    "    sets the seeds for python, numpy, and pytoch (CPU & GPU) \n",
    "    \"\"\"\n",
    "    # python random module\n",
    "    random.seed(seed)\n",
    "    # numpy\n",
    "    np.random.seed(seed)\n",
    "    # pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    # pytorch (GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Seeds set to {seed}\") \n",
    "\n",
    "# setting up directory paths and loading the dataset\n",
    "script_directory = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd() \n",
    "dataset_path = os.path.join(script_directory, dataset_dir_name) \n",
    "def load_data(file_path: str): \n",
    "    \"\"\"\n",
    "    Reads a csv and returns a numpy array of all the data \n",
    "    SETS THE INDEX TO THE TIME COLUMN\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path) \n",
    "    df.set_index('time',inplace=True)  \n",
    "    data = df.to_numpy() \n",
    "    return data   \n",
    "dataset = load_data(os.path.join(dataset_path, dataset_filename)) \n",
    "print(\"shape of the dataset: \", dataset.shape)  \n",
    "\n",
    "# data plot directory \n",
    "data_plot_path = os.path.join(dataset_path, data_plot_dir_name) \n",
    "os.makedirs(data_plot_path, exist_ok=True) \n",
    "\n",
    "# plotting  \n",
    "# 3d trajectory plot \n",
    "plot_name = \"x_y_z plot.png\"  \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(dataset[:, ee_x_index], dataset[:, ee_y_index], dataset[:, ee_z_index], s=5)\n",
    "ax.scatter(dataset[:, midsection_x_index], dataset[:, midsection_y_index], dataset[:, midsection_z_index], s=5)\n",
    "ax.set_zlim(-0.4, 0)\n",
    "ax.set_xlabel('EE_X[m]')\n",
    "ax.set_ylabel('EE_Y[m]')\n",
    "ax.set_zlabel('EE_Z[m]')\n",
    "ax.set_title('3D EE Trajectory')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(data_plot_path, plot_name), dpi=300, bbox_inches=\"tight\")\n",
    "plt.close() \n",
    "# 3d ee trajectory plot \n",
    "plot_name = \"ee_x_y_z plot.png\"  \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(dataset[:, ee_x_index], dataset[:, ee_y_index], dataset[:, ee_z_index], s=5)\n",
    "ax.set_zlim(-0.4, 0)\n",
    "ax.set_xlabel('EE_X[m]')\n",
    "ax.set_ylabel('EE_Y[m]')\n",
    "ax.set_zlabel('EE_Z[m]')\n",
    "ax.set_title('3D EE Trajectory')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(data_plot_path, plot_name), dpi=300, bbox_inches=\"tight\")\n",
    "plt.close() \n",
    "# 2d ee trajectory plot \n",
    "plot_name = \"ee_x_y_plot.png\"  \n",
    "plt.figure()\n",
    "plt.scatter(dataset[:,ee_x_index],dataset[:,ee_y_index], s=5)\n",
    "plt.xlabel('EE_x[m]') \n",
    "plt.ylabel('EE_y[m]') \n",
    "plt.title('2D EE Trajectory')  \n",
    "plt.tight_layout()  \n",
    "plt.savefig(os.path.join(data_plot_path, plot_name), dpi=300, bbox_inches=\"tight\") \n",
    "plt.close()  \n",
    "# actuator inputs plots \n",
    "for i in range(input_stop_index) : \n",
    "    plot_name = f\"u{i+1}_plot.png\"   \n",
    "    plt.figure()\n",
    "    plt.plot(dataset[:,i])  \n",
    "    plt.xlabel('Sample') \n",
    "    plt.ylabel(f\"Actuator {i+1} Value\") \n",
    "    plt.title(f\"Actuator {i+1} Inputs\")  \n",
    "    plt.tight_layout()  \n",
    "    plt.savefig(os.path.join(data_plot_path, plot_name), dpi=300, bbox_inches=\"tight\") \n",
    "    plt.close()  \n",
    "# state plots \n",
    "for i in range(state_start_index,state_stop_index) : \n",
    "    plot_name = f\"x_{i+1}_plot.png\"   \n",
    "    plt.figure()\n",
    "    plt.plot(dataset[:,i])  \n",
    "    plt.xlabel('Sample') \n",
    "    plt.ylabel(f\"State {i+1} Value\") \n",
    "    plt.title(f\"State {i+1} Values\")  \n",
    "    plt.tight_layout()  \n",
    "    plt.savefig(os.path.join(data_plot_path, plot_name), dpi=300, bbox_inches=\"tight\") \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c2453",
   "metadata": {},
   "source": [
    "shifting the data and train, validation and testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9b589ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape:  (36379, 3)\n",
      "states shape:  (36379, 6)\n",
      "U and X train split shape:  (25465, 3) (25465, 6)\n",
      "U and X valid split shape:  (5456, 3) (5456, 6)\n",
      "U and X test split shape:  (5458, 3) (5458, 6)\n"
     ]
    }
   ],
   "source": [
    "# shifting the dataset \n",
    "U_unshifted = dataset[:,input_start_index:input_stop_index] \n",
    "X_unshifted = dataset[:,state_start_index:state_stop_index] \n",
    "U = U_unshifted[:-1,:] \n",
    "X = X_unshifted[1:,:] \n",
    "print(\"inputs shape: \", U.shape) \n",
    "print(\"states shape: \", X.shape)  \n",
    "\n",
    "# train, validation and testing split \n",
    "def train_valid_test_split(dataset: np.array, train_percent: int, valid_percent: int) : \n",
    "    \"\"\"\n",
    "    splits a dataset into training, validation and testing sets\n",
    "    \"\"\"\n",
    "    len_data = len(dataset) \n",
    "    train_size = int(train_percent*len_data) \n",
    "    valid_size = int(valid_percent*len_data) \n",
    "    train_data = dataset[0:train_size] \n",
    "    valid_data = dataset[train_size:train_size+valid_size] \n",
    "    test_data = dataset[train_size+valid_size:] \n",
    "    return train_data, valid_data, test_data  \n",
    "U_train, U_valid, U_test = train_valid_test_split(dataset=U, train_percent=train_percent, valid_percent=valid_percent) \n",
    "X_train, X_valid, X_test = train_valid_test_split(dataset=X, train_percent=train_percent, valid_percent=valid_percent) \n",
    "print(\"U and X train split shape: \", U_train.shape, X_train.shape) \n",
    "print(\"U and X valid split shape: \", U_valid.shape, X_valid.shape) \n",
    "print(\"U and X test split shape: \", U_test.shape, X_test.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c9142",
   "metadata": {},
   "source": [
    "scaling the datasets and saving the scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3eb0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "input_scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "state_scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "input_scaler.fit(U_train)   \n",
    "state_scaler.fit(X_train) \n",
    "U_train_scaled = input_scaler.transform(U_train) \n",
    "U_valid_scaled = input_scaler.transform(U_valid) \n",
    "U_test_scaled = input_scaler.transform(U_test)  \n",
    "X_train_scaled = state_scaler.transform(X_train) \n",
    "X_valid_scaled = state_scaler.transform(X_valid) \n",
    "X_test_scaled = state_scaler.transform(X_test)  \n",
    "# saving the scalers  \n",
    "network_data_dir_path = os.path.join(script_directory, network_data_dir_name) \n",
    "os.makedirs(network_data_dir_path, exist_ok=True)\n",
    "import pickle\n",
    "input_scaler_filename = \"input_scaler_lines.pkl\" \n",
    "state_scaler_filename = \"state_scaler_lines.pkl\" \n",
    "with open(os.path.join(network_data_dir_path, input_scaler_filename), \"wb\") as file : \n",
    "    pickle.dump(input_scaler, file=file)\n",
    "with open(os.path.join(network_data_dir_path, state_scaler_filename), \"wb\") as file : \n",
    "    pickle.dump(state_scaler, file=file) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
